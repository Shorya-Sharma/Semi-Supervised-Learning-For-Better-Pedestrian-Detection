{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_labeled_part.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM8WlIEypGCW4+DOwnSa4fo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliciachenw/11785-project/blob/main/load_labeled_part.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUR4KAN_kJc-"
      },
      "source": [
        "\n",
        "\n",
        "# **split the training set into labeled and unlabeled**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoGJFoRZidZk",
        "outputId": "69936496-c1c2-4b9b-f3ae-78c51b9c03e4"
      },
      "source": [
        "# load google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q286Yap0izPV"
      },
      "source": [
        "import os, json, random\n",
        "\n",
        "def split_labeled_unlabeled(img_dir, split=None):\n",
        "  \"\"\"\n",
        "  randomly divide the data in img_dir into labeledand unlabeled\n",
        "  :param: img_dir: directory saving the \n",
        "  :param: split: ratio of labeled data to all data\n",
        "  \"\"\"\n",
        "  json_file = os.path.join(img_dir, \"thermal_annotations.json\")\n",
        "  with open(json_file) as f:\n",
        "    json_data = json.load(f)\n",
        "    imgs_info = json_data[\"info\"]\n",
        "    imgs_categories = json_data[\"categories\"]\n",
        "    imgs_license = json_data[\"licenses\"]\n",
        "    imgs_anns = json_data[\"annotations\"]\n",
        "    imgs_infos = json_data[\"images\"]\n",
        "  \n",
        "  dataset_dicts = []\n",
        "  pointer = 0\n",
        "\n",
        "  for idx, v in enumerate(imgs_infos):\n",
        "    record = {}\n",
        "    record[\"image_id\"] = idx\n",
        "    record[\"images\"] = v\n",
        "    objs = []\n",
        "    while pointer < len(imgs_anns):\n",
        "      annotation = imgs_anns[pointer]\n",
        "      if annotation[\"image_id\"] == record[\"image_id\"]:\n",
        "        if annotation[\"category_id\"] == 1:\n",
        "          obj = annotation\n",
        "          objs.append(obj)\n",
        "        pointer += 1\n",
        "      else:\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "        break\n",
        "  \n",
        "  if split != None:\n",
        "    length_data = len(dataset_dicts)\n",
        "    random_train = int(split * length_data)\n",
        "    random.shuffle(dataset_dicts)\n",
        "    train_dicts = dataset_dicts[:random_train]\n",
        "    vld_dicts = dataset_dicts[random_train:]\n",
        "\n",
        "    with open(img_dir + '/labeled.json', 'w') as fp:\n",
        "      training_images = []\n",
        "      training_annotations = []\n",
        "      for instance in train_dicts:\n",
        "        training_images.append(instance[\"images\"])\n",
        "        training_annotations = training_annotations + instance[\"annotations\"]\n",
        "\n",
        "      training_dicts = {}\n",
        "      training_dicts[\"info\"] = imgs_info\n",
        "      training_dicts[\"categories\"] = imgs_categories\n",
        "      training_dicts[\"license\"] = imgs_license\n",
        "      training_dicts[\"annotations\"] = training_annotations\n",
        "      training_dicts[\"images\"] = training_images\n",
        "      json.dump(training_dicts, fp, indent=4)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAlsudy_jMoz"
      },
      "source": [
        "dataset_dir = \"/content/gdrive/My Drive/FLIR/\"\n",
        "split_labeled_unlabeled(dataset_dir + \"/train\", 0.2)"
      ],
      "execution_count": 3,
      "outputs": []
    }
  ]
}